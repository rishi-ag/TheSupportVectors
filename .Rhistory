2, 2, byrow = TRUE)
return(VCmatrix)
}
#Function generating random draws from a normal distribution with input: n=number of obs to be simulated, their means = muXY and the Covariance Matrix = sigma XY
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# Defining Correlation for hippopotamus
sigmaHippo <- sigmaXY(rho=0.8, sdX=0.7, sdY=0.1)
sigmaHippo
# Defining Correlation for rhinoceros
sigmaRhino <- sigmaXY(rho=0.5, sdX=0.3, sdY=0.2)
sigmaRhino
# Defining the number of observations and the means'vector for the 3 groups of animals
noHippo <- noRhino <- 10; muHippo <- c(4, 15); muRhino <- c(7,20)
# Drawing samples for creating three 50x2 Matrices of Obs. using the genBVN function by introducing the pre- defined values of parameters
Hippo <- genBVN(noHippo, muHippo, sigmaHippo, seed = 7852)
Rhino <- genBVN(noRhino, muRhino, sigmaRhino, seed = 7853)
# Collecting everything in the 150x3 data frame: animalsDf
animalsDf <- as.data.frame(rbind(Hippo,Rhino))
Animal <- c(rep(-1, noHippo), rep(1, noRhino))
animalsDf <- cbind(animalsDf, Animal)
colnames(animalsDf) <- c("weight", "height", "Animal")
head(animalsDf)
dim(animalsDf)
animalsDf
w = matrix(0 , ncol=2)
stop_point <- FALSE
i <- 1
iter <- 1
while (!stop_point) {
print(i)
print(w)
print(iter)
# getting the points
x <- animalsDf[i, 1:2]
y <- animalsDf[i, 3]
# getting the predicted class
if (sum(w * x) > 0 ) {
g <- 1
}else {
g <- -1
}
# updating the weights if prediction incorrect
if (g != y) {
w = w + y * x
}
# check if stopping cond satisfied
pred = as.matrix(animalsDf[, 1:2]) %*% t(w)
pred[pred <= 0] <- -1
pred[pred > 0] <- 1
if (identical(as.numeric(pred),animalsDf[, 3])) {
stop_point <- TRUE
print(stop_point)
}
# update the counter
if (i > 19) {
i <- 1
iter <- iter + 1
} else {
i <- i+1
}
}
library(ggmap)
library(ggplot2)
URL<-"http://www.econ.upf.edu/~michael/visualdata/data/flickrindicator2011barcelona.csv"
data_raw<-getURL(URL)
install.packages("RCurl")
library(RCurl)
URL<-"http://www.econ.upf.edu/~michael/visualdata/data/flickrindicator2011barcelona.csv"
data_raw<-getURL(URL)
datavis <-read.csv(textConnection(data_raw))
class(datavis)
ggmap(map) + ggtitle("Photos taken during the year") + theme(plot.title = element_text(size = 30,colour="black")) +
geom_point(data = datavis, aes(x = longitude, y = latitude), col = "blue", bg = "blue", alpha = 0.01, na.rm = TRUE, size = 2, shape = 21) +
guides(fill=FALSE, alpha=FALSE, size=FALSE)
library(ggmap)
ggmap(map) + ggtitle("Photos taken during the year") + theme(plot.title = element_text(size = 30,colour="black")) +
geom_point(data = datavis, aes(x = longitude, y = latitude), col = "blue", bg = "blue", alpha = 0.01, na.rm = TRUE, size = 2, shape = 21) +
guides(fill=FALSE, alpha=FALSE, size=FALSE)
map <- get_map(location = c(lon = mean(dataviz$longitude),
lat = mean(dataviz$latitude)),
zoom = 13,
maptype = "roadmap",
scale = 2)
map <- get_map(location = c(lon = mean(datavis$longitude),
lat = mean(datavis$latitude)),
zoom = 13,
maptype = "roadmap",
scale = 2)
ggmap(map) + ggtitle("Photos taken during the year") + theme(plot.title = element_text(size = 30,colour="black")) +
geom_point(data = datavis, aes(x = longitude, y = latitude), col = "blue", bg = "blue", alpha = 0.01, na.rm = TRUE, size = 2, shape = 21) +
guides(fill=FALSE, alpha=FALSE, size=FALSE)
ggmap(map) + ggtitle("Photos taken during the year") + theme(plot.title = element_text(size = 30,colour="black")) +
geom_point(data = datavis, aes(x = longitude, y = latitude), col = "blue", bg = "blue", alpha = 0.005, na.rm = TRUE, size = 2, shape = 21) +
guides(fill=FALSE, alpha=FALSE, size=FALSE)
# Group by Spanish people and foreigners
Spain <- subset(datavis, datavis$user_country == "BCN" | datavis$user_country == "CAT" | datavis$user_country == "MAD")
Spain$country <- "Spain"
Foreigners <- subset(datavis, datavis$user_country != "BCN" & datavis$user_country != "CAT" & datavis$user_country != "MAD")
Foreigners$country <- "Foreigners"
Foreigners <- Foreigners[1:47354]
Spain <- subset(datavis, datavis$user_country == "BCN" | datavis$user_country == "CAT" | datavis$user_country == "MAD")
Spain$country <- "Spain"
Foreigners <- subset(datavis, datavis$user_country != "BCN" & datavis$user_country != "CAT" & datavis$user_country != "MAD")
Foreigners$country <- "Foreigners"
Foreigners <- Foreigners[1:47354,]
ggmap(map) + ggtitle("Spain vs Foreigners") + theme(plot.title = element_text(size = 30,colour="black")) +
geom_point(data = datavis_2, aes(x = longitude, y = latitude, colour = country, bg = country), alpha = 0.01, na.rm = TRUE, size = 3, shape = 21) +
guides(colour = guide_legend(override.aes = list(alpha = 1, size = 3)))
datavis_2 <- rbind(Spain, Foreigners)
ggmap(map) + ggtitle("Spain vs Foreigners") + theme(plot.title = element_text(size = 30,colour="black")) +
geom_point(data = datavis_2, aes(x = longitude, y = latitude, colour = country, bg = country), alpha = 0.01, na.rm = TRUE, size = 3, shape = 21) +
guides(colour = guide_legend(override.aes = list(alpha = 1, size = 3)))
if (!require("rmarkdown")) install.packages("rmarkdown")
if (!require("mvtnorm")) install.packages("mvtnorm")
if (!require("ggplot2")) install.packages("ggplot2")
# setting up some key things for our report
filename <- "ML_seminar1"
outputAsHTML <- FALSE
outputAsPDF <- TRUE
if (outputAsHTML) {
opts_chunk$set(dev = 'svg')
options(xtable.type = 'html')
options(xtable.include.rownames = FALSE)
options(xtable.comment = FALSE)
}
if (outputAsPDF) {
opts_chunk$set(dev = 'pdf')
options(xtable.type = 'latex')
options(xtable.include.rownames = FALSE)
options(xtable.comment = FALSE)
}
# cleaning before starting
# rm(list=ls())
# getwd()
# setwd("/home/hrvoje/Dropbox/Teaching/UPF_MachineLearning_2015/Seminar1/")
```
# Exercises
1. Create a 2-dimensional data set with three categories, train a discriminant function and illustrate the boundaries in a figure. Be careful with the coding scheme!
2. By using R packages Shiny and Shinyapps, create an interactive web application that illustrates the results of your classification algorithm, together with the decision boundaries.
Submit your solution for the first exercise as an .Rmd file and the solution for the second exercise as a link to your application. Submit them to my email address: hrvoje.stojic@upf.edu.
--------
## Intro to Discriminant functions - General Remarks
To illustrate discriminant functions I used a general example of two continuous variables (height and weight) for predicting the class between 3 different animals: elephants, hippopotamus and rhinoceros. In the following the whole procedure is described in detail.
## Simple categorization problem
Let us assume that weight and height are both normally distributed variables, not necessarily independent from each other.Since we have a 2-dimensional case (*height* and *weight*) our joint distribution is goverened by the following parameters:
1. The vector of the means of heights and weights for the 3 animals
2. The Covariance Matrix which includes the SDs of the variables as well as the correlation (Ï) between the 2 variables.
```{r, MVN_example_corr, comment=TRUE, echo=TRUE}
## Assuming different correlations between height and weight for the 3 animals and create wrapper functions
#  Covariance Matrix function
sigmaXY <- function(rho, sdX, sdY) {
covTerm <- rho * sdX * sdY
# Creating Variance-Covariance Matrix
VCmatrix <- matrix(c(sdX^2, covTerm, covTerm, sdY^2),
2, 2, byrow = TRUE)
return(VCmatrix)
}
#Function generating random draws from a normal distribution with input: n=number of obs to be simulated, their means = muXY and the Covariance Matrix = sigma XY
genBVN <- function(n = 1, seed = NA, muXY=c(0,1), sigmaXY=diag(2)) {
if(!is.na(seed)) set.seed(seed)
rdraws <- rmvnorm(n, mean = muXY, sigma = sigmaXY)
return(rdraws)
}
# Defining Correlation for hippopotamus
sigmaHippo <- sigmaXY(rho=0.8, sdX=0.7, sdY=0.1)
sigmaHippo
# Defining Correlation for rhinoceros
sigmaRhino <- sigmaXY(rho=0.5, sdX=0.3, sdY=0.2)
sigmaRhino
# Defining the number of observations and the means'vector for the 3 groups of animals
noHippo <- noRhino <- 10; muHippo <- c(4, 15); muRhino <- c(7,20)
# Drawing samples for creating three 50x2 Matrices of Obs. using the genBVN function by introducing the pre- defined values of parameters
Hippo <- genBVN(noHippo, muHippo, sigmaHippo, seed = 7852)
Rhino <- genBVN(noRhino, muRhino, sigmaRhino, seed = 7853)
# Collecting everything in the 150x3 data frame: animalsDf
animalsDf <- as.data.frame(rbind(Hippo,Rhino))
Animal <- c(rep(-1, noHippo), rep(1, noRhino))
animalsDf <- cbind(animalsDf, Animal)
colnames(animalsDf) <- c("weight", "height", "Animal")
head(animalsDf)
dim(animalsDf)
animalsDf
w = matrix(0 , ncol=2)
stop_point <- FALSE
i <- 1
iter <- 1
while (!stop_point) {
print(i)
print(w)
print(iter)
# getting the points
x <- animalsDf[i, 1:2]
y <- animalsDf[i, 3]
# getting the predicted class
if (sum(w * x) > 0 ) {
g <- 1
}else {
g <- -1
}
# updating the weights if prediction incorrect
if (g != y) {
w = w + y * x
}
# check if stopping cond satisfied
pred = as.matrix(animalsDf[, 1:2]) %*% t(w)
pred[pred <= 0] <- -1
pred[pred > 0] <- 1
if (identical(as.numeric(pred),animalsDf[, 3])) {
stop_point <- TRUE
print(stop_point)
}
# update the counter
if (i > 19) {
i <- 1
iter <- iter + 1
} else {
i <- i+1
}
}
library(maps)
install.packages("maps")
install.packages("maps")
library(maps)
library(mapproj)
install.packages("mapproj")
install.packages("mapproj")
library(mapproj)
# Load data
quakes <- read.csv('http://datasets.flowingdata.com/earthquakes1974.csv')
summary(quakes)
# Draw map
par(mar=c(0,0,0,0))
map("world", col="orange", bg="#000000", fill=FALSE, interior=TRUE, lwd=0.5, projection="cylequalarea", par=0, wrap=TRUE)
map("world", col="blue", bg="#000000", fill=FALSE, interior=TRUE, lwd=0.5, projection="cylequalarea", par=0, wrap=TRUE)
map("greece", col="blue", bg="#000000", fill=FALSE, interior=TRUE, lwd=0.5, projection="cylequalarea", par=0, wrap=TRUE)
map("USA", col="blue", bg="#000000", fill=FALSE, interior=TRUE, lwd=0.5, projection="cylequalarea", par=0, wrap=TRUE)
# Add points
ptsproj <- mapproject(quakes$longitude, quakes$latitude)
points(ptsproj, pch=20, cex=0.15, col="#ffffff40")
# Circle the highest magnitude quakes
quakes.o <- quakes[order(quakes$mag, decreasing=TRUE),]
quakes.o
quakes.o <- quakes[order(quakes$mag, decreasing=TRUE),]
quakes.o
majorpts <- mapproject(quakes.o$longitude[1:10], quakes.o$latitude[1:10])
symbols(majorpts, circles=rep(0.03, 10), add=TRUE, inches=FALSE, fg="green", lwd=2)
map("world", col="red", bg="#000000", fill=FALSE, interior=TRUE, lwd=0.5, projection="cylequalarea", par=0, wrap=TRUE)
blue
map("world", col="blue", bg="#000000", fill=FALSE, interior=TRUE, lwd=0.5, projection="cylequalarea", par=0, wrap=TRUE)
# Add points
ptsproj <- mapproject(quakes$longitude, quakes$latitude)
points(ptsproj, pch=20, cex=0.15, col="#ffffff40")
# Circle the highest magnitude quakes
quakes.o <- quakes[order(quakes$mag, decreasing=TRUE),]
majorpts <- mapproject(quakes.o$longitude[1:10], quakes.o$latitude[1:10])
symbols(majorpts, circles=rep(0.03, 10), add=TRUE, inches=FALSE, fg="green", lwd=2)
names(quakes)
data{}
data{}
data(maps){}
data{}(maps)
data{(maps)}
rbinom(1,5)
rbinom(3,5,0,2)
rbinom(3,5,0.2)
rbinom(3,5,0.2)
rbinom(3,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.2)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.8)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbinom(2,5,0.5)
rbern(10, 0.5)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.1)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.2)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(20,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(1,5,0.3)
rbinom(100,5,0.3)
rbinom(100,5,0.3)
rbinom(100,5,0.3)
rbinom(100,5,0.3)
setwd("~/GitHub/TheSupportVectors")
source("code/library.R")
train <- get.train.data()
str(train)
train.label <- train[[1]]
train.label <- train[[1]] # getting the labels of the features of the training set
train.feat_st <- train[[3]] # getting the standardized features of the training set
pca <- prcomp(x=train.feat_st)
?prcomp
print(pca)
plot(pca, type = "l")
dim(pca)
str(pca)
retr_values <- pca$x
dim(retr_values)
covpca<-cov(retr_values)
setwd("~/GitHub/TheSupportVectors")
source("code/library.R")
```
#Step 1: Getting the labels and the standardized features
```{r}
train <- get.train.data()
train.label <- train[[1]] # getting the labels of the features of the training set
#labels_df <- as.data.frame(train.label)
#train.feat <- train[[2]]
train.feat_st <- train[[3]] # getting the standardized features of the training set
pca <- prcomp(x=train.feat_st)
print(pca)
SD_princomp <- print(pca)
StDev_princomp <- print(pca)
remove(SD_princomp)
str(StDev_princomp)
?prcomp
plot(pca, type = "l")
plot(pca)
plot(pca)
summary(pca)
