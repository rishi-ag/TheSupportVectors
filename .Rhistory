#' @param coefs Initial coefficients for the perceptron (x2 coef, x1 coef, b coef)
#' @return Data frame with predictions and distances
#' @export
classify.perceptron<-function(data,coefs){
data$i<-rep(1,length(data$Y))
cdata<-c(1,2,5)
pred<-rep(NA,dim(data)[1])
dist<-rep(NA,dim(data)[1])
int<-as.numeric(-(coefs[3]/coefs[1])) #intercept
# Classifiy and distance
for(i in 1:length(data$Y)){
pred[i]<-sign(sum(coefs*data[i,cdata]))
dist[i]<-abs((coefs[1]*(data[i,1]-int)+coefs[2]*data[i,2])
/sqrt(sum(coefs[1:2]^2)))
}
dist<-unlist(dist)
return(data.frame(pred=pred,dist=dist))
}
#' Radius of data function
#'
#' Calculates max radius of bivariatedata as distance to its mean
#'
#' @param data Data frame, first two columns are x2, x1
#' @return Numeric maximum distance from a point to the centroid of data
#' @export
calc.radius<-function(data){
radius<-0
mean<-colMeans(data[,1:2])
for (i in 1:dim(data)[1]){
dist<-sum((mean-data[i,1:2])^2)
if (dist>radius) {radius<-dist}
}
return(sqrt(radius))
}
#' Optimal margin function
#'
#' Calculates optimal margin separation of bivariatedata as distance to linear svm classifier line
#'
#' @param data Data frame, first two columns are x2, x1,class is Y (-1,+1)
#' @return Numeric optimal classification margin
#' @export
calc.gamma<-function(data){
names(data)[1:2]<-c("weight","height")
gamma<-0
svm.model <- svm(Y ~ height+weight, data=data, type='C-classification',
kernel='linear',scale=FALSE)
border<-data[svm.model$index,]
w <- t(svm.model$coefs) %*% svm.model$SV
b <- -svm.model$rho
p <- svm.model$SV
intp<--b/w[1,2]
sl<--w[1,1]/w[1,2]
svm.coefs<-c(1,-sl,-intp)
names(svm.coefs)<-c("weight","height","i")
norm.w<-sqrt(svm.coefs[1]^2+svm.coefs[2]^2)
gamma<-sum(svm.coefs[1:2]*(border[1,1:2]-c(intp,0)))/norm.w
#check wih other point uniqueness
# gamma<-sum(svm.coefs[1:2]*border[2,1:2])/norm.w
return(as.numeric(abs(gamma)))
}
#-------------------------
#### Algorithm ###########
#-------------------------
#Data generation case separation
data<-data.gen(number=100,overlap=F)
coefs<-perceptron(data,50000)$coefs
plot<-plot.perceptron(data,coefs)
plot
out<-classify.perceptron(data,coefs)
head(out)
# Plot max margin solution with linear support vector model
svm.model <- svm(Y ~ height+weight, data=data, type='C-classification',
kernel='linear',scale=FALSE)
border<-data[svm.model$index,]
border$Distance<-c("svm")
w <- t(svm.model$coefs) %*% svm.model$SV
b <- -svm.model$rho
p <- svm.model$SV
intp<--b/w[1,2]
sl<--w[1,1]/w[1,2]
svm.coefs<-c(1,-sl,-intp)
# plot perceptron and linear svm lines
plot+geom_abline(slope=sl,intercept=intp,colour="red")
#Errors
Errors<-(length(data$Y)-sum(out$pred*data$Y))/2
Errors/lenght(data$Y)#percent errors
# Plot with min dist point
minpoint<-data[which.min(out$dist),]
minpoint$Distance<-c('minimum')
plot.perceptron(data,coefs,minpoint,plotmin=T)
#### Case overlap data
data<-data.gen(number=100,overlap=T)
coefs<-perceptron(data,20000)$coefs
plot<-plot.perceptron(data,coefs)
plot
out<-classify.perceptron(data,coefs)
#Errors
Errors<-(length(data$Y)-sum(out$pred*data$Y))/2
Errors/length(data$Y) #percent errors
# Plot with min dist point
minpoint<-data[which.min(out$dist),]
minpoint$Distance<-c('minimum')
plot.perceptron(data,coefs,minpoint,plotmin=T)
# Check efect of radius and minimum distance on number of iterations
# Generate random data and check
data<-data.gen(number=100,overlap=F)
#including points in sequence along centers of data,
# affects distance and radius at same time
c1center<-c(3, 150)
c2center<-c(c(10, 80))
mean<-colMeans(data[,1:2])
slpct<-(c1center[1]-c2center[1])/(c1center[2]-c2center[2])
intct<-c1center[1]-c1center[2]*slpct
#seq of points from center of class 2 of data to center of data,
#generate each time closer points
n_each<-5
intpoint<-seq(80,mean[2],length.out=n_each)
intpoint<-as.data.frame(cbind(intpoint*slpct+intct,intpoint))
intpoint<-intpoint[1:(n_each-1),] #remove point at mean
names(intpoint)<-c("weight","height")
# idem but outer
outpoint<- seq(0,80,length.out=n_each)
outpoint<-as.data.frame(cbind(outpoint*slpct+intct,outpoint))
outpoint<-outpoint[1:(n_each-1),] #remove last point repeated
names(outpoint)<-c("weight","height")
#join
points<-rbind(outpoint,intpoint)
#plot to check it
ggplot() +
geom_point(data = data, aes(x = height, y = weight,
colour=Animal, fill=Animal)) +
geom_point(data=points,aes(x=height,y=weight))
# for each new center of class 1, play with increasing or decreasin SD in order
# to generate data with diferent margin of classification and radius
n_sd<-5
n_xclass<-100
max_iter<-30000
sd<-data.frame(sdx2=seq(1,6,length.out=n_sd),sdx1=seq(4,20,length.out=n_sd))
results<-matrix(NA,dim(points)[1]*dim(sd)[1],ncol=5)
for(i in (1:dim(points)[1])){
for (j in (1:dim(sd)[1])){
cat('\n Point ',i,' SD ',j)
data <- data.gen(n_xclass,meanc2= as.numeric(points[i,]),
sdc2=as.numeric(sd[j,]),overlap=F)
percp<-perceptron(data,max_iter)
# Radius and gamma calculations
gamma<-calc.gamma(data)
radius<-calc.radius(data)
results[j+(i-1)*dim(sd)[1],]<-c(i,j,radius,gamma,percp$iter)
}
}
# Final plot
results<-as.data.frame(results)
names(results)<-c("center2","sd2","radius","gamma","iterations")
results<-results[results$iterations<max_iter,]
results$rad_dist<-(results$radius/results$gamma)^2
ggplot(results, aes(x=radius, y=iterations)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+
ggtitle("Performance of percerptron algorithm")
ggplot(results, aes(x=gamma, y=iterations)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+
ggtitle("Performance of percerptron algorithm")
ggplot(results, aes(x=rad_dist, y=iterations)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+
xlab(expression(paste((radius/gamma)^bold("2"))))+
ggtitle("Performance of percerptron algorithm")
data<-data.frame(rnorm(10),rnorm(10))
calc.radius(data)
plot(data)
plot(data,asp=1)
mean<-colMeans(data[,1:2])
mean
results
library(tree)
library(tree)
install.packages("tree")
install.packages("rpart")
?rpart
library(rpart)
library(tree)
ir.tr <- tree(Species ~., iris)
ir.tr
summary(ir.tr)
plot(ir.tr)
fit <- tree(Species ~., iris)
fit
summary(fit)
plot(fit, uniform=TRUE, main="Classification Tree")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
plot(fit, main="Classification Tree")
text(fit,  all=TRUE, cex=.8)
str(iris)
data<-iris
fit2 <- rpart(data$Species ~ ., method="class")
data<-iris
fit2 <- rpart(Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data, method="class")
plot(fit, uniform=TRUE, main="Classification Tree")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
rpart.control(maxdepth=1)
fit2 <- rpart(Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data, method="class")
plot(fit, uniform=TRUE, main="Classification Tree")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
control<-rpart.control(maxdepth=1)
fit2 <- rpart(Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data, control=control,method="class")
plot(fit, uniform=TRUE, main="Classification Tree")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
control<-rpart.control(maxdepth=1)
fit2 <- rpart(Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data, control=rpart.control(maxdepth=1),
params=list(split="gini"),method="class")
plot(fit2, uniform=TRUE, main="Classification Tree")
text(fit2, use.n=TRUE, all=TRUE, cex=.8)
fit2 <- rpart(Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data, control=control,
method="class")
plot(fit2, uniform=TRUE, main="Classification Tree")
text(fit2, use.n=TRUE, all=TRUE, cex=.8)
str(data)
out<-predict(fit2,data[,-5])
head(out)
head(out,50)
tail(out,50)
tail(out,100)
out<-predict(fit2,data[,-5],type="class")
tail(out,100)
ntrees<-c(1:(dim(data)[1]))
devtools::install_github("rstudio/rmarkdown")
rmarkdown::render('in.md',
output_format=pdf_document(latex_engine='xelatex')
)
if(!require("randomForest"))install.packages("randomForest")
if(!require("doParallel"))install.packages("doParallel")
if(!require("reshape2"))install.packages("reshape2")
if(!require("ggplot2"))install.packages("ggplot2")
if(!require("caret"))install.packages("caret")
if(!require("dplyr"))install.packages("dplyr")
if(!require("ggthemes"))install.packages("ggthemes")
setwd("D:/master/kaggle/TheSupportVectors")
source("code/library.R")
# Function for random forest
compare.k <- function(k, train, label) {
#compare errors for different k maximum variables on features
model <- randomForest(x = train, y = label, mtry = k)
# error rate is computed from out of bag elements, so it's a cross-val error
rfor.error<-sum(model$predicted!=label)/length(label)
return(rfor.error)
}
unify<-function(data,vector,text){
nobs<-dim(data)[1]
out<-rep(0,nobs)
for (j in 1:nobs){
for (i in seq_along(vector)){
out[j]<-paste0(out[j],data[[paste0(text,as.character(vector[i]))]][j])
}
}
return(as.factor(out))
}
#get data for rforest
train.data <- get.train.data()
labels <- train.data[[1]]
features <- train.data[[2]]
str(train.data)
features<-features[1:5000,]
labels<-labels[1:5000]
mink<-round(sqrt(dim(features)[2])/2)
maxk<-round(dim(features)[2]/2)
#model<-randomForest(x = features.train.red, y = labels.train)
#error<-sum(model$predicted!=labels.train)/length(labels.train)
#set up cluster
cores <- detectCores()
cl <- makeCluster(cores)
clusterExport(cl, list("labels", "features","mink","maxk",
"compare.k", "randomForest"), envir = environment())
registerDoParallel(cl)
#call function to compare k error rates on features and standardised features
system.time(rfor.perf<- parSapply(cl, seq(mink,maxk, 1),
function(x) compare.k(x, features, labels)))
stopCluster(cl)
rfor.perf
comparison <- data.frame(k = seq(mink, maxk, 2), feat.err = rfor.perf)
comparison.long <- melt(data = comparison, id.vars = "k",
measure.vars = c("feat.err"),
variable.name = "feature_type", value.name = "error")
#plot
plot1 <- ggplot(data = comparison.long, aes(x = k,y = error, color = feature_type )) +
geom_line(size = 0.5) +
geom_point(size = 3) +
scale_x_continuous(breaks= seq(mink,maxk,1)) +
ggtitle("Mtry error ") +
scale_color_wsj(name  ="Feature Type", labels=c("Raw"))
plot1
head(features)
head(labels)
model <- randomForest(x = features, y = labels, mtry = maxk)
head(model$predicted)
class(labels)
labels <- train.data[[1]]
class(labels)
labels <- as.factor(train.data[[1]])
str(features)
library("dplyr")
#set WD
#setwd("C:/Users/Rishabh/Documents/GitHub/TheSupportVectors/")
# setwd("D:/master/kaggle/TheSupportVectors")
preprocess <- function() {
#Function produces three files. One where A test label file. Two features file. One where
#Read Data
data.train <- read.csv(file = "data/Kaggle_Covertype_training.csv", nrows = 50000, header = T)
data.test <- read.csv(file = "data/Kaggle_Covertype_test.csv", header = T, nrows = 100000)
#Process and standardise test and train data
#Seperate labels and features
labels.train <- factor(select(data.train, Cover_Type)[,1])
#remove labels and id
features.train <- select(data.train, -Cover_Type, -id)
features.train.std <- features.train
features.test <- select(data.test, -id)
features.test.std <- features.test
#Standardise function
#Convert aspect to radians
features.train.std[,2] <- features.train.std[,2] * (pi/180)
features.test.std[,2] <- features.test.std[,2] * (pi/180)
#There are 10 quantitative variables. Standardise them. Aspect converted to sin and cos
features.train.std[,c(1, 3:10)] <- apply(features.train.std[,c(1, 3:10)], 2, function(x) (x - mean(x)) / sd(x))
features.train.std$sin<-sin(features.train.std[,2])
features.train.std$cos<-cos(features.train.std[,2])
features.test.std[,c(1, 3:10)] <- apply(features.test.std[,c(1, 3:10)], 2, function(x) (x - mean(x)) / sd(x))
features.test.std$sin<-sin(features.test.std[,2])
features.test.std$cos<-cos(features.test.std[,2])
#rename standardised variables
names(features.train.std)[1:10] <- paste0(names(features.train.std)[1:10], "_std")
names(features.test.std)[1:10] <- paste0(names(features.test.std)[1:10], "_std")
#remove aspect var
features.train.std <- select(features.train.std, -aspect_std)
features.test.std <- select(features.test.std, -aspect_std)
#save files to /data
write.csv(x = features.train.std, file = "data/train_features_std.csv", row.names = FALSE)
write.csv(x = labels.train, file = "data/train_labels.csv", row.names = FALSE)
write.csv(x = features.train, file = "data/train_features.csv", row.names = FALSE)
write.csv(x = features.test, file = "data/test_features.csv", row.names = FALSE)
write.csv(x = features.test.std, file = "data/test_features_std.csv", row.names = FALSE)
}
get.train.data <- function() {
labels <- read.csv("data/train_labels.csv", header = T,
nrows = 50000)[,1]
features <- read.csv("data/train_features.csv", header = T, nrows = 50000)
features.std <- read.csv("data/train_features_std.csv", header = T, nrows = 50000)
return(list(labels, features, features.std))
}
get.test.data <- function() {
features <- read.csv("data/test_features.csv", header = T)
features.std <- read.csv("data/test_features_std.csv", header = T)
return(list(features, features.std))
}
source("code/library.R")
train.data <- get.train.data()
head(train.data)
features <- train.data[[2]]
str(features)
source("code/library.R")
train.data <- get.train.data()
class(train.data[[1]])
features <- train.data[[3]] #standarized data
str(features)
names(features)[10:44]
names(features)[10:54]
features<-features[1:5000,]
features[,10:53]<-as.factor(features[,10:53])
apply(10:11,function(i) as.factor(features[,i])
)
prova<-apply(features[,10:53],2,as.factor)
head(prova)
str(prova)
class(prova)
prova[1,1]
prova[1,2]
prova<-as.data.frame(apply(features[,10:53],2,as.factor))
class(prova)
str(prova)
train.data <- get.train.data()
labels <- as.factor(train.data[[1]])
features <- train.data[[3]] #standarized data
features[,10:53]<-as.data.frame(apply(features[,10:53],2,as.factor))
#subset data
features<-features[1:5000,]
labels<-labels[1:5000]
str(features)
model <- randomForest(x = features, y = labels, mtry = maxk)
head(labels)
head(model$predicted)
#set up cluster
cores <- detectCores()
cl <- makeCluster(cores)
clusterExport(cl, list("labels", "features","mink","maxk",
"compare.k", "randomForest"), envir = environment())
registerDoParallel(cl)
#call function to compare k error rates on features and standardised features
system.time(rfor.perf<- parSapply(cl, seq(mink,maxk, 1),
function(x) compare.k(x, features, labels)))
stopCluster(cl)
if(!require("randomForest"))install.packages("randomForest")
if(!require("doParallel"))install.packages("doParallel")
if(!require("reshape2"))install.packages("reshape2")
if(!require("ggplot2"))install.packages("ggplot2")
if(!require("caret"))install.packages("caret")
if(!require("dplyr"))install.packages("dplyr")
if(!require("ggthemes"))install.packages("ggthemes")
setwd("D:/master/kaggle/TheSupportVectors")
source("code/library.R")
# Function for random forest
compare.k <- function(k, train, label) {
#compare errors for different k maximum variables on features
model <- randomForest(x = train, y = label, mtry = k)
# error rate is computed from out of bag elements, so it's a cross-val error
rfor.error<-sum(model$predicted!=label)/length(label)
return(rfor.error)
}
unify<-function(data,vector,text){
nobs<-dim(data)[1]
out<-rep(0,nobs)
for (j in 1:nobs){
for (i in seq_along(vector)){
out[j]<-paste0(out[j],data[[paste0(text,as.character(vector[i]))]][j])
}
}
return(as.factor(out))
}
#get data for rforest
train.data <- get.train.data()
labels <- as.factor(train.data[[1]])
features <- train.data[[3]] #standarized data
features[,10:53]<-as.data.frame(apply(features[,10:53],2,as.factor))
#subset data
features<-features[1:5000,]
labels<-labels[1:5000]
# Bounds for mtry parameter (max of variables per step)
mink<-round(sqrt(dim(features)[2])/2)
maxk<-round(dim(features)[2]/2)
cores <- detectCores()
cl <- makeCluster(cores)
clusterExport(cl, list("labels", "features","mink","maxk",
"compare.k", "randomForest"), envir = environment())
registerDoParallel(cl)
#call function to compare k error rates on features and standardised features
system.time(rfor.perf<- parSapply(cl, seq(mink,maxk, 1),
function(x) compare.k(x, features, labels)))
stopCluster(cl)
comparison <- data.frame(k = seq(mink, maxk, 2), feat.err = rfor.perf)
rfor.perf
comparison <- data.frame(k = seq(mink, maxk, 1), feat.err = rfor.perf)
comparison.long <- melt(data = comparison, id.vars = "k",
measure.vars = c("feat.err"),
variable.name = "feature_type", value.name = "error")
#plot
plot1 <- ggplot(data = comparison.long, aes(x = k,y = error, color = feature_type )) +
geom_line(size = 0.5) +
geom_point(size = 3) +
scale_x_continuous(breaks= seq(mink,maxk,1)) +
ggtitle("Mtry error ") +
scale_color_wsj(name  ="Feature Type", labels=c("Raw"))
plot1
best.k = comparison$k[which.min(comparison$feat.err)]
best.k
rm(prova)
sqrt(55)
model$err.rate
plot(model$err.rate)
plot(1:500,model$err.rate[,1])
dim(model$err.rate)
model$err.rate[1,]
class(model$err.rate[1,])
rfor.error<-c(rfor.error,model$err.rate[dim(model$err.rate)[1],])
rfor.error<-sum(model$predicted!=label)/length(label)
rfor.error<-sum(model$predicted!=labels)/length(labels)
rfor.error<-c(rfor.error,model$err.rate[dim(model$err.rate)[1],])
rfor.error
class(rfor.error)
table(labels)
model$confussion
model$confusion
model$votes
head(model$votes)
compare.k <- function(k, train, label) {
#compare errors for different k maximum variables on features
model <- randomForest(x = train, y = label, mtry = k)
# error rate is computed from out of bag elements, so it's a cross-val error
rfor.error<-sum(model$predicted!=label)/length(label)
return(c(rfor.error,model$err.rate[dim(model$err.rate)[1],]))
}
mink<-round(sqrt(dim(features)[2])/2)
maxk<-round(dim(features)[2]/2)
# Initial check
#set up cluster
cores <- detectCores()
cl <- makeCluster(cores)
clusterExport(cl, list("labels", "features","mink","maxk",
"compare.k", "randomForest"), envir = environment())
registerDoParallel(cl)
#call function to compare k error rates on features and standardised features
system.time(rfor.perf<- parSapply(cl, seq(mink,maxk, 1),
function(x) compare.k(x, features, labels)))
stopCluster(cl)
rfor.per
rfor.perf
class(rfor.perf)
comparison <- data.frame(k = seq(mink, maxk, 1), feat.err = t(rfor.perf))
head(comparison)
