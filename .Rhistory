orderMat <- as.matrix(t(apply(distMat, 1, order))[,2:(k+1)])
#Predict classes
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(data[x,4]) > 0.5))
#Calculate error
error.table <- table(predictedClass1, data[,4])
return(list(predictedClass = predictedClass1, error.table = error.table))
}
trainData <- gen2c2dMixture(noObs=c(5000, 5000), seed=1234)
trained.output <- train.class(trainData, k)
trained.output$error.table
predict.class <- function(trainData, newData, trainLabel, k = 1, p = 2) {
#calculate distance matrix
distMat <- apply(trainData[,1:2], 1, function(row) calc_dist(row, newdata[,1:2], p))
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
#Predict classes
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
return(predictedClass1)
}
a <- predict.class(trainData, dataset, trainData[,4])
predict.class <- function(trainData, newData, trainLabel, k = 1, p = 2) {
#calculate distance matrix
distMat <- apply(trainData[,1:2], 1, function(row) calc_dist(row, newdata[,1:2], p))
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
#Predict classes
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
return(predictedClass1)
}
a <- predict.class(trainData, dataset, trainData[,4])
predict.class <- function(trainData, newData, trainLabel, k = 1, p = 2) {
#calculate distance matrix
distMat <- apply(trainData[,1:2], 1, function(row) calc_dist(row, newData[,1:2], p))
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
#Predict classes
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
return(predictedClass1)
}
a <- predict.class(trainData, dataset, trainData[,4])
head(testResults$predictedClasses)
head(a)
testResults <- kNN_classifier(data=datasetTest[,1:2], trueClasses=dataset[,4],
memory=dataset[,1:2], k=k, p=2, type="predict")
a <- predict.class(trainData, dataset, trainData[,4], k = k)
head(testResults$predictedClasses)
head(a)
head(testResults$predictedClasses, 20)
head(a, 20)
distMat <- apply(trainData[,1:2], 1, function(row) calc_dist(row, newData[,1:2], p))
newData = dataset
distMat <- apply(trainData[,1:2], 1, function(row) calc_dist(row, newData[,1:2], p))
orderMat <- as.matrix(t(apply(distMat, 1, order))
orderMat <- as.matrix(t(apply(distMat, 1, order)))
orderMat <- as.matrix(t(apply(distMat, 1, order)))
dim(orderMat)
distMat <- apply(trainData[,1:2], 1, function(row) calc_dist(row, newData[,1:2], p))
orderMat <- as.matrix(apply(distMat, 1, order)[,1:k])
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainData[x,4]) > 0.5))
head(testResults$predictedClasses, 20)
head(predictedClass1, 20)
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
dim(orderMatrix)
dim(orderMat)
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
predict.class <- function(trainData, newData, trainLabel, k = 1, p = 2) {
#calculate distance matrix
distMat <- apply(newData[,1:2], 1, function(row) calc_dist(row, trainData[,1:2], p))
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
#Predict classes
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
return(predictedClass1)
}
a <- predict.class(trainData, dataset, trainData[,4], k = k)
newData = dataset
distMat <- apply(newData[,1:2], 1, function(row) calc_dist(row, trainData[,1:2], p))
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
dim(orderMat)
orderMat <- as.matrix((apply(distMat, 1, order))[,1:k])
dim(orderMat)
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainData[x,4]) > 0.5))
distMat <- apply(newData[,1:2], 1, function(row) calc_dist(row, trainData[,1:2], p))
orderMat <- as.matrix((apply(distMat, 1, order))#[,1:k])
)
dim(orderMat)
distMat1 <- apply(newData[,1:2], 1, function(row) calc_dist(row, trainData[1,1:2], p))
orderMat1 <- as.matrix((apply(as.matrix(distMat1), 1, order))#[,1:k])
)
View(orderMat1)
distMat <- apply(newData[,1:2], 1, function(row) calc_dist(row, trainData[,1:2], p))
dim(distMat)
View(distMat[1:10, 1:10])
View(distMat[1:10, 1:10])
orderMat <- as.matrix(t(apply(distMat, 2, order))[,1:k])
View(orderMat1)
View(orderMat)
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
trainLabel = trainData[,4]
predictedClass1 <- as.numeric(apply(orderMat, 1, function(x) mean(trainLabel[x]) > 0.5))
datasetTest <- gen2c2dMixture(noObs=c(5000, 5000), seed=1234)
k <- 15  # odd number
p <- 2  # Manhattan (1), Euclidean (2) or Chebyshev (Inf)
testResults <- kNN_classifier(data=datasetTest[,1:2], trueClasses=dataset[,4],
memory=dataset[,1:2], k=k, p=2, type="predict")
head(testResults$predictedClasses)
trainData <- gen2c2dMixture(noObs=c(5000, 5000), seed=1234)
kNN_classifier <- function(data, trueClasses, memory=NULL,
k=1, p=2, type="train") {
# test the inputs
library(assertthat)
not_empty(data); not_empty(trueClasses);
if (type=="train") {
assert_that(nrow(data)==length(trueClasses))
}
is.string(type); assert_that(type %in% c("train", "predict"))
is.count(k);
assert_that(p %in% c(1, 2, Inf))
if (type=="predict") {
assert_that(not_empty(memory) &
ncol(memory)==ncol(data) &
nrow(memory)==length(trueClasses))
}
# Compute the distance between each point and all others
noObs <- nrow(data)
# if we are making predictions on the test set based on the memory,
# we compute distances between each test observation and observations
# in our memory
if (type=="train") {
predictionId <- 1
distMatrix <- matrix(NA, noObs, noObs)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
# computing distances between the probe and exemplars in the
# training data
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(data -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(data - probeExpanded), 1, max)
}
}
} else if (type == "predict") {
predictionId <- 0
noMemory <- nrow(memory)
distMatrix <- matrix(NA, noObs, noMemory)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noMemory), nrow=noMemory)
# computing distances between the probe and exemplars in the memory
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(memory -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(memory - probeExpanded), 1, max)
}
}
}
# Sort the distances in increasing numerical order and pick the first
# k elements
neighbors <- apply(distMatrix, 1, order)
# Compute and return the most frequent class in the k nearest neighbors
prob <- predictedClasses <-  rep(NA, noObs)
for (obs in 1:noObs) {
prob[obs] <- mean(trueClasses[neighbors[(1+predictionId):
(k+predictionId), obs]])
if(prob[obs] > 0.5) {
predictedClasses[obs] <- 1
} else {
predictedClasses[obs] <- 0
}
}
# examine the performance, available only if training
if (type=="train") {
errorCount <- table(predictedClasses, trueClasses)
accuracy <- mean(predictedClasses==trueClasses)
} else if (type == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClasses,
prob=prob,
accuracy=accuracy,
errorCount=errorCount,
orderMatrix = neighbors))
}
testResults <- kNN_classifier(data=datasetTest[,1:2], trueClasses=dataset[,4],
memory=dataset[,1:2], k=k, p=2, type="predict")
View(testResults$orderMatrix[1:10, 10:10])
View(testResults$orderMatrix[1:10, 1:10])
distMat <- apply(newData[,1:2], 1, function(row) calc_dist(row, trainData[,1:2], p))
dim(distMat)
distMat <- as.matrix(t(apply(newData[,1:2], 1, function(row) calc_dist(row, trainData[,1:2], p))))
dim(distMat)
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
dim(orderMat)
View(orderMat[1:10, 1:10])
noMemory <- nrow(memory)
kNN_classifier <- function(data, trueClasses, memory=NULL,
k=1, p=2, type="train") {
# test the inputs
library(assertthat)
not_empty(data); not_empty(trueClasses);
if (type=="train") {
assert_that(nrow(data)==length(trueClasses))
}
is.string(type); assert_that(type %in% c("train", "predict"))
is.count(k);
assert_that(p %in% c(1, 2, Inf))
if (type=="predict") {
assert_that(not_empty(memory) &
ncol(memory)==ncol(data) &
nrow(memory)==length(trueClasses))
}
# Compute the distance between each point and all others
noObs <- nrow(data)
# if we are making predictions on the test set based on the memory,
# we compute distances between each test observation and observations
# in our memory
if (type=="train") {
predictionId <- 1
distMatrix <- matrix(NA, noObs, noObs)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
# computing distances between the probe and exemplars in the
# training data
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(data -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(data - probeExpanded), 1, max)
}
}
} else if (type == "predict") {
predictionId <- 0
noMemory <- nrow(memory)
distMatrix <- matrix(NA, noObs, noMemory)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noMemory), nrow=noMemory)
# computing distances between the probe and exemplars in the memory
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(memory -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(memory - probeExpanded), 1, max)
}
}
}
# Sort the distances in increasing numerical order and pick the first
# k elements
neighbors <- apply(distMatrix, 2, order)
# Compute and return the most frequent class in the k nearest neighbors
prob <- predictedClasses <-  rep(NA, noObs)
for (obs in 1:noObs) {
prob[obs] <- mean(trueClasses[neighbors[(1+predictionId):
(k+predictionId), obs]])
if(prob[obs] > 0.5) {
predictedClasses[obs] <- 1
} else {
predictedClasses[obs] <- 0
}
}
# examine the performance, available only if training
if (type=="train") {
errorCount <- table(predictedClasses, trueClasses)
accuracy <- mean(predictedClasses==trueClasses)
} else if (type == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClasses,
prob=prob,
accuracy=accuracy,
errorCount=errorCount,
orderMatrix = neighbors))
}
datasetTest <- gen2c2dMixture(noObs=c(5000, 5000), seed=1234)
k <- 15  # odd number
p <- 2  # Manhattan (1), Euclidean (2) or Chebyshev (Inf)
testResults <- kNN_classifier(data=datasetTest[,1:2], trueClasses=dataset[,4],
memory=dataset[,1:2], k=k, p=2, type="predict")
kNN_classifier <- function(data, trueClasses, memory=NULL,
k=1, p=2, type="train") {
# test the inputs
library(assertthat)
not_empty(data); not_empty(trueClasses);
if (type=="train") {
assert_that(nrow(data)==length(trueClasses))
}
is.string(type); assert_that(type %in% c("train", "predict"))
is.count(k);
assert_that(p %in% c(1, 2, Inf))
if (type=="predict") {
assert_that(not_empty(memory) &
ncol(memory)==ncol(data) &
nrow(memory)==length(trueClasses))
}
# Compute the distance between each point and all others
noObs <- nrow(data)
# if we are making predictions on the test set based on the memory,
# we compute distances between each test observation and observations
# in our memory
if (type=="train") {
predictionId <- 1
distMatrix <- matrix(NA, noObs, noObs)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
# computing distances between the probe and exemplars in the
# training data
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(data -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(data - probeExpanded), 1, max)
}
}
} else if (type == "predict") {
predictionId <- 0
noMemory <- nrow(memory)
distMatrix <- matrix(NA, noObs, noMemory)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noMemory), nrow=noMemory)
# computing distances between the probe and exemplars in the memory
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(memory -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(memory - probeExpanded), 1, max)
}
}
}
# Sort the distances in increasing numerical order and pick the first
# k elements
neighbors <- apply(distMatrix, 1, order)
# Compute and return the most frequent class in the k nearest neighbors
prob <- predictedClasses <-  rep(NA, noObs)
for (obs in 1:noObs) {
prob[obs] <- mean(trueClasses[neighbors[(1+predictionId):
(k+predictionId), obs]])
if(prob[obs] > 0.5) {
predictedClasses[obs] <- 1
} else {
predictedClasses[obs] <- 0
}
}
# examine the performance, available only if training
if (type=="train") {
errorCount <- table(predictedClasses, trueClasses)
accuracy <- mean(predictedClasses==trueClasses)
} else if (type == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClasses,
prob=prob,
accuracy=accuracy,
errorCount=errorCount,
orderMatrix = neighbors))
}
distMat <- (apply( trainData[,1:2], 1, function(row) calc_dist(row, newData[,1:2], p))
)
dim(distMat)
orderMat <- as.matrix(t(apply(distMat, 1, order))[,1:k])
View(orderMat[1:10, 1:10])
View(orderMat[1:10, 1:k])
kNN_classifier <- function(data, trueClasses, memory=NULL,
k=1, p=2, type="train") {
# test the inputs
library(assertthat)
not_empty(data); not_empty(trueClasses);
if (type=="train") {
assert_that(nrow(data)==length(trueClasses))
}
is.string(type); assert_that(type %in% c("train", "predict"))
is.count(k);
assert_that(p %in% c(1, 2, Inf))
if (type=="predict") {
assert_that(not_empty(memory) &
ncol(memory)==ncol(data) &
nrow(memory)==length(trueClasses))
}
# Compute the distance between each point and all others
noObs <- nrow(data)
# if we are making predictions on the test set based on the memory,
# we compute distances between each test observation and observations
# in our memory
if (type=="train") {
predictionId <- 1
distMatrix <- matrix(NA, noObs, noObs)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noObs), nrow=noObs)
# computing distances between the probe and exemplars in the
# training data
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(data -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(data - probeExpanded), 1, max)
}
}
} else if (type == "predict") {
predictionId <- 0
noMemory <- nrow(memory)
distMatrix <- matrix(NA, noObs, noMemory)
for (obs in 1:noObs) {
# getting the probe for the current observation
probe <- as.numeric(data[obs,])
probeExpanded <- matrix(rep(probe, each=noMemory), nrow=noMemory)
# computing distances between the probe and exemplars in the memory
if (p %in% c(1,2)) {
distMatrix[obs, ] <- (rowSums((abs(memory -
probeExpanded))^p) )^(1/p)
} else if (p==Inf) {
distMatrix[obs, ] <- apply(abs(memory - probeExpanded), 1, max)
}
}
}
# Sort the distances in increasing numerical order and pick the first
# k elements
neighbors <- apply(distMatrix, 1, order)
# Compute and return the most frequent class in the k nearest neighbors
prob <- predictedClasses <-  rep(NA, noObs)
for (obs in 1:noObs) {
prob[obs] <- mean(trueClasses[neighbors[(1+predictionId):
(k+predictionId), obs]])
if(prob[obs] > 0.5) {
predictedClasses[obs] <- 1
} else {
predictedClasses[obs] <- 0
}
}
# examine the performance, available only if training
if (type=="train") {
errorCount <- table(predictedClasses, trueClasses)
accuracy <- mean(predictedClasses==trueClasses)
} else if (type == "predict") {
errorCount <- NA
accuracy <- NA
}
# return the results
return(list(predictedClasses=predictedClasses,
prob=prob,
accuracy=accuracy,
errorCount=errorCount,
distMatrix = distMatrix))
}
datasetTest <- gen2c2dMixture(noObs=c(5000, 5000), seed=1234)
k <- 15  # odd number
p <- 2  # Manhattan (1), Euclidean (2) or Chebyshev (Inf)
testResults <- kNN_classifier(data=datasetTest[,1:2], trueClasses=dataset[,4],
memory=dataset[,1:2], k=k, p=2, type="predict")
dim(testResults$distMatrix)
View(t(testResults$distMatrix)[1:10, 1:10])
View(distMat[1:10, 1:10])
library(gg)
library("ggplot2")
options(echo=TRUE)
args <- commandArgs(trailingOnly = TRUE)
print(args)
date <- as.Date(args[1])
par1 <- as.numeric(args[2])
par2 <- as.numeric(args[3])
name <- args[4]
x <- rnorm(1000, mean=par1, sd=par2)
pdf(paste(name,".pdf",sep=""))
plot(x)
title(main=as.character(date))
dev.off()
summary(x)
A <- c(1.12,1.53,0.29,4.91,5.46,0.52,0.32,2.19,1.51,2.81,2.59,0.77,1.87,11.63)
B <- c(0.83,1.16,0.40,1.55,1.42,0.46,0.47,1.95,0.56,0.59,0.19)
A <- c(1.12,1.53,0.29,4.91,5.46,0.52,0.32,2.19,1.51,2.81,2.59,0.77,1.87,11.63)
B <- c(0.83,1.16,0.40,1.55,1.42,0.46,0.47,1.95,0.56,0.59,0.19)
Summary(A)
summary(A)
summary(B)
boxplot(A, B)
library(mvtnorm)
mvtnorm::rmvnorm
?mvtnorm::rmvnorm
data.train <- read.csv(file = "data/Kaggle_Covertype_training.csv", nrows = 50000, header = T)
setwd("C:/Users/Rishabh/Documents/GitHub/TheSupportVectors/")
data.train <- read.csv(file = "data/Kaggle_Covertype_training.csv", nrows = 50000, header = T)
labels.train <- factor(select(data.train, Cover_Type)[,1])
library(dplyr)
labels.train <- factor(select(data.train, Cover_Type)[,1])
features.train <- select(data.train, -Cover_Type, -id)
names(features.train)
head(features.train$aspect)
install.packages("circular")
library("circular")
circular::mean.circular(features.train$aspect)
?circular::mean.circular
circular::mean.circular(features.train$aspect)
summary(features.train$aspect)
circular(runif(50, circular(0), pi))
?arctan
sin.aspect <- sin(features.train$aspect)
